Let's proceed with the next major advancement: **Multi-Modal Financial Analysis**. This will add earnings call analysis, document understanding, and advanced data extraction capabilities.

### **Step 1: Audio Processing for Earnings Calls**


# **ðŸŽ¤ The AI Earnings Call Detective: Audio Analysis System!**

let's look at one of the **most exciting and cutting-edge** applications of AI in finance - analyzing earnings calls! This system can **listen to company earnings calls** and automatically extract insights, just like a team of Wall Street analysts!


Here, we're going to create our **AI Earnings Call Analyst** that:
1. **ðŸ‘‚ Listens to audio** (earnings call recordings)
2. **ðŸ“ Transcribes speech to text** (using OpenAI's Whisper)
3. **ðŸ‘¥ Identifies speakers** (CEO, CFO, analysts)
4. **ðŸ˜Š Analyzes sentiment** (positive/negative tone)
5. **ðŸ’° Extracts financial metrics** (revenue, EPS, guidance)
6. **ðŸ“Š Structures everything** for analysis

**Think of it like:** Having an AI analyst who never sleeps, listens to every earnings call, and remembers every number mentioned!

---

## **ðŸŽ¯ Why Earnings Call Analysis Matters**

### **The Problem:**
- **Length:** Earnings calls = 60-90 minutes
- **Volume:** 1000s of companies Ã— 4 quarters/year
- **Information overload:** Key insights buried in conversations
- **Human limitation:** Analysts can't listen to everything

### **The AI Solution:**
```
60-minute earnings call â†’ 5-minute AI analysis
CEO mentions "revenue grew 15%" â†’ AI extracts and highlights
CFO sounds cautious â†’ AI detects negative sentiment
Analyst asks tough question â†’ AI flags as important
```

**Result:** Investors get key insights instantly!

---

## **ðŸ”§ The Three-Part System**

### **Part 1: EarningsCallProcessor (The Conductor)**
### **Part 2: SpeakerDiarization (The Who's Who)**
### **Part 3: AudioSentimentAnalyzer (The Mood Detector)**


let's start with the first part. import whiper






































**A 1-hour call becomes searchable text!**

---

## **ðŸ‘¥ Part 2: Speaker Identification (Who Said What?)**

### **The Challenge:**
```
[0:00-5:00] Good morning... (CEO)
[5:00-20:00] Our financial results... (CFO)  
[20:00-60:00] Q&A session... (Various Analysts)
```

**Humans:** Recognize voices, know roles
**AI:** Needs to figure it out from context!

### **The Smart Heuristics:**
```python
def infer_speaker_role(self, text: str, speaker_id: str) -> str:
    text_lower = text.lower()
    
    if 'our strategy' in text_lower: return 'CEO'
    if 'financial results' in text_lower: return 'CFO'
    if 'question' in text_lower: return 'Analyst'
    if 'thank you' in text_lower: return 'Operator'
```

**Why this works:**
- **CEOs** talk about strategy, vision, market
- **CFOs** talk numbers: revenue, EPS, margins
- **Analysts** ask questions
- **Operators** manage the call flow

**Example detection:**
```
Text: "Our strategy is to expand into new markets..."
AI: "That sounds like a CEO!"
```




#### Create `src/financial_rag/processing/audio_processor.py`

```python
import whisper

# **What is Whisper?**
# - OpenAI's speech recognition model
# - **Open source and free!**
# - Works in 99 languages
# - Great accuracy even with financial jargon


import torch
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import io
import os
from loguru import logger
from financial_rag.config import config

class EarningsCallProcessor:
    """Process earnings call audio and extract insights"""
    
    def __init__(self):
        self.model = None
        self.speaker_diarization = SpeakerDiarization()
        self.sentiment_analyzer = AudioSentimentAnalyzer()
        
    def load_models(self):
        """Load Whisper model for speech recognition"""
        try:
            if not self.model:
                device = "cuda" if torch.cuda.is_available() else "cpu"
                self.model = whisper.load_model("base", device=device)
                logger.success("Whisper model loaded successfully")
        except Exception as e:
            logger.error(f"Error loading Whisper model: {e}")
            raise
    
    def transcribe_earnings_call(self, audio_path: str) -> Dict[str, Any]:
        """Transcribe earnings call audio with speaker identification"""
        try:
            self.load_models()
            
            # Transcribe audio
            result = self.model.transcribe(
                audio_path,
                language='en',
                fp16=False  # More stable on CPU
            )
            
            # Perform speaker diarization
            segments_with_speakers = self.speaker_diarization.identify_speakers(
                audio_path, result['segments']
            )
            
            # Analyze sentiment per speaker
            sentiment_analysis = self.sentiment_analyzer.analyze_sentiment(
                segments_with_speakers
            )
            
            # Extract key metrics
            key_metrics = self.extract_financial_metrics(result['text'])
            
            return {
                'transcript': result['text'],
                'segments': segments_with_speakers,
                'sentiment_analysis': sentiment_analysis,
                'key_metrics': key_metrics,
                'duration': result.get('duration', 0),
                'language': result.get('language', 'en')
            }
            
        except Exception as e:
            logger.error(f"Error transcribing earnings call: {e}")
            raise
    

# **Output structure:**
# ```json
# {
#   "text": "Good morning everyone...",
#   "segments": [
#     {"start": 0.0, "end": 5.2, "text": "Good morning..."},
#     {"start": 5.2, "end": 12.5, "text": "Our revenue was..."}
#   ],
#   "language": "en",
#   "duration": 3600.5
# }
# ```

    def extract_financial_metrics(self, transcript: str) -> Dict[str, Any]:
        """Extract financial metrics from earnings call transcript"""
        import re
        
        metrics = {
            'revenue': self.extract_revenue(transcript),
            'eps': self.extract_eps(transcript),
            'guidance': self.extract_guidance(transcript),
            'growth_rates': self.extract_growth_rates(transcript),
            'key_announcements': self.extract_announcements(transcript)
        }
        
        return metrics
    
    def extract_revenue(self, text: str) -> List[Dict]:
        """Extract revenue figures from transcript"""
        revenue_patterns = [
            r'revenue\s*(?:of|was|\$)\s*(\d+\.?\d*)\s*(billion|million|B|M)',
            r'(\d+\.?\d*)\s*(billion|million|B|M)\s*in\s*revenue',
            r'revenue\s*(?:growth|increased|decreased)\s*(?:by|to)\s*(\d+\.?\d*)%'
        ]
        
        revenues = []
        for pattern in revenue_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                revenues.append({
                    'value': match.group(1),
                    'unit': match.group(2) if len(match.groups()) > 1 else 'unknown',
                    'context': text[max(0, match.start()-50):match.end()+50]
                })
        
        return revenues

# **What it finds:**
# - "Revenue was $10.5 billion" â†’ `{"value": "10.5", "unit": "billion"}`
# - "We achieved $1.2B in revenue" â†’ `{"value": "1.2", "unit": "B"}`
# - "Revenue grew by 15%" â†’ `{"value": "15", "unit": "%"}`

# ### **The Five Metric Categories:**
# 1. **Revenue** - Top line growth
# 2. **EPS** - Earnings per share (profitability)
# 3. **Guidance** - Future expectations
# 4. **Growth Rates** - Percentage changes
# 5. **Announcements** - New products, partnerships

# **Example extraction:**
# ```
# Transcript snippet: "Q3 revenue was $89.5 billion, up 8% year-over-year. 
# EPS came in at $1.46, beating estimates. For Q4, we expect revenue 
# between $92-95 billion."

# Extracted:
# - Revenue: $89.5B (+8%)
# - EPS: $1.46 (beat)
# - Guidance: Q4 revenue $92-95B
# ```




    def extract_eps(self, text: str) -> List[Dict]:
        """Extract EPS figures from transcript"""
        eps_patterns = [
            r'eps\s*(?:of|was|\$)\s*(\d+\.?\d*)',
            r'earnings\s*per\s*share\s*(?:of|was|\$)\s*(\d+\.?\d*)',
            r'(\d+\.?\d*)\s*eps'
        ]
        
        eps_figures = []
        for pattern in eps_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                eps_figures.append({
                    'value': float(match.group(1)),
                    'context': text[max(0, match.start()-50):match.end()+50]
                })
        
        return eps_figures
    
    def extract_guidance(self, text: str) -> Dict[str, Any]:
        """Extract forward guidance from transcript"""
        guidance_keywords = [
            'guidance', 'outlook', 'expect', 'forecast', 'project',
            'anticipate', 'target', 'estimate'
        ]
        
        guidance_sentences = []
        sentences = re.split(r'[.!?]+', text)
        
        for sentence in sentences:
            if any(keyword in sentence.lower() for keyword in guidance_keywords):
                guidance_sentences.append(sentence.strip())
        
        return {
            'sentences': guidance_sentences,
            'confidence': len(guidance_sentences) / max(len(sentences), 1)
        }
    
    def extract_growth_rates(self, text: str) -> List[Dict]:
        """Extract growth rate mentions"""
        growth_pattern = r'(\d+\.?\d*)%\s*(?:growth|increase|decrease|change)'
        
        growth_rates = []
        matches = re.finditer(growth_pattern, text, re.IGNORECASE)
        
        for match in matches:
            growth_rates.append({
                'rate': float(match.group(1)),
                'context': text[max(0, match.start()-30):match.end()+30]
            })
        
        return growth_rates
    
    def extract_announcements(self, text: str) -> List[str]:
        """Extract key announcements"""
        announcement_indicators = [
            'announce', 'launch', 'introduce', 'release', 'new',
            'partnership', 'acquisition', 'investment', 'expansion'
        ]
        
        announcements = []
        sentences = re.split(r'[.!?]+', text)
        
        for sentence in sentences:
            if any(indicator in sentence.lower() for indicator in announcement_indicators):
                # Filter out very short sentences
                if len(sentence.split()) > 5:
                    announcements.append(sentence.strip())
        
        return announcements


class SpeakerDiarization:
    """Identify different speakers in earnings calls"""
    
    def identify_speakers(self, audio_path: str, segments: List[Dict]) -> List[Dict]:
        """Identify speakers in audio segments (simplified implementation)"""
        # In production, use pyannote.audio or similar
        # For now, use a rule-based approach
        
        speaker_segments = []
        current_speaker = "Speaker_1"
        
        for i, segment in enumerate(segments):
            text = segment.get('text', '').lower()
            
            # Simple speaker change detection based on content
            if i > 0:
                prev_text = segments[i-1].get('text', '').lower()
                
                # Speaker change indicators
                change_indicators = [
                    'thank you', 'questions', 'operator', 'next question',
                    'good morning', 'good afternoon', 'hello everyone'
                ]
                
                if any(indicator in text for indicator in change_indicators):
                    current_speaker = f"Speaker_{len(set([s['speaker'] for s in speaker_segments])) + 1}"
            
            speaker_segments.append({
                **segment,
                'speaker': current_speaker,
                'speaker_role': self.infer_speaker_role(text, current_speaker)
            })
        
        return speaker_segments
    
    def infer_speaker_role(self, text: str, speaker_id: str) -> str:
        """Infer speaker role based on content"""
        text_lower = text.lower()
        
        # CEO indicators
        if any(phrase in text_lower for phrase in [
            'our strategy', 'company vision', 'long-term', 'shareholders',
            'transformative', 'market leadership'
        ]):
            return 'CEO'
        
        # CFO indicators
        elif any(phrase in text_lower for phrase in [
            'financial results', 'revenue', 'eps', 'margin', 'guidance',
            'cash flow', 'balance sheet', 'capital allocation'
        ]):
            return 'CFO'
        
        # Analyst indicators
        elif any(phrase in text_lower for phrase in [
            'question', 'could you', 'can you', 'what about', 'how about'
        ]):
            return 'Analyst'
        
        # Operator indicators
        elif any(phrase in text_lower for phrase in [
            'thank you', 'next question', 'question and answer'
        ]):
            return 'Operator'
        
        return 'Unknown'


class AudioSentimentAnalyzer:
    """Analyze sentiment in audio segments"""
    
    def analyze_sentiment(self, segments: List[Dict]) -> Dict[str, Any]:
        """Analyze sentiment per speaker and overall"""
        from textblob import TextBlob
        
        speaker_sentiments = {}
        overall_sentiment = {
            'positive_segments': 0,
            'negative_segments': 0,
            'neutral_segments': 0,
            'average_polarity': 0,
            'average_subjectivity': 0
        }
        
        polarities = []
        subjectivities = []
        
        for segment in segments:
            text = segment.get('text', '')
            speaker = segment.get('speaker', 'Unknown')
            
            if text.strip():
                blob = TextBlob(text)
                polarity = blob.sentiment.polarity
                subjectivity = blob.sentiment.subjectivity
                
                polarities.append(polarity)
                subjectivities.append(subjectivity)
                
                # Categorize sentiment
                if polarity > 0.1:
                    sentiment = 'positive'
                    overall_sentiment['positive_segments'] += 1
                elif polarity < -0.1:
                    sentiment = 'negative'
                    overall_sentiment['negative_segments'] += 1
                else:
                    sentiment = 'neutral'
                    overall_sentiment['neutral_segments'] += 1
                
                # Track by speaker
                if speaker not in speaker_sentiments:
                    speaker_sentiments[speaker] = {
                        'polarity_sum': 0,
                        'subjectivity_sum': 0,
                        'segment_count': 0,
                        'sentiment_distribution': {'positive': 0, 'negative': 0, 'neutral': 0}
                    }
                
                speaker_sentiments[speaker]['polarity_sum'] += polarity
                speaker_sentiments[speaker]['subjectivity_sum'] += subjectivity
                speaker_sentiments[speaker]['segment_count'] += 1
                speaker_sentiments[speaker]['sentiment_distribution'][sentiment] += 1
        
        # Calculate averages
        if polarities:
            overall_sentiment['average_polarity'] = sum(polarities) / len(polarities)
            overall_sentiment['average_subjectivity'] = sum(subjectivities) / len(subjectivities)
        
        # Finalize speaker sentiments
        for speaker, data in speaker_sentiments.items():
            data['average_polarity'] = data['polarity_sum'] / data['segment_count']
            data['average_subjectivity'] = data['subjectivity_sum'] / data['segment_count']
            del data['polarity_sum']
            del data['subjectivity_sum']
        
        return {
            'overall': overall_sentiment,
            'by_speaker': speaker_sentiments
        }
```

### **Step 2: Document Understanding & Table Extraction**
# **ðŸ“Š The AI Financial Document Decoder: Table and Chart Analysis!**

Good morning class! Today we're looking at one of the **most challenging and powerful** parts of financial AI - extracting structured data from financial documents! This system can **read PDF reports, extract tables, and understand charts** just like a human analyst!

---

## **ðŸš€ What This Code Does**

This code creates a **Financial Document Detective** that:
1. **ðŸ“„ Reads PDF files** (annual reports, earnings releases)
2. **ðŸ—ƒï¸ Extracts tables** (income statements, balance sheets)
3. **ðŸ’° Converts to numbers** ($1.2B â†’ 1,200,000,000)
4. **ðŸ“ˆ Analyzes trends** (revenue growth, profit margins)
5. **ðŸ“Š Understands structure** (knows what each table means)
6. **ðŸ” Generates insights** (automated analysis)

**Think of it like:** Having an army of interns who never sleep, reading every financial document, and extracting every number into a perfect spreadsheet!

---

## **ðŸŽ¯ The Big Problem: Unstructured Financial Data**

### **The Reality:**
```
ðŸ“„ 100-page PDF annual report
â”œâ”€â”€ 25 tables (income statement, balance sheet, etc.)
â”œâ”€â”€ 15 charts (revenue trends, market share)
â”œâ”€â”€ 50 pages of text (analysis, risks, strategy)
â””â”€â”€ All mixed together in different formats!
```

### **Human Analyst:**
- Takes **hours** to read and extract
- **Mistakes** in manual data entry
- **Inconsistent** formatting
- **Can't scale** to thousands of companies

### **AI Solution:**
```
PDF â†’ 5 seconds â†’ Clean structured data
Table extraction â†’ Automatic analysis
Chart reading â†’ Trend detection
All data â†’ Queryable database
```

---

## **ðŸ”§ The Three-Layer Extraction System**

### **Layer 1: FinancialDocumentProcessor (The Coordinator)**
### **Layer 2: FinancialTableAnalyzer (The Number Cruncher)**
### **Layer 3: ChartProcessor (The Visual Reader)**

---







## **ðŸŽ“ Real-World Example: Apple Annual Report**

### **Input:**
```
ðŸ“„ Apple 10-K (200 pages PDF)
Page 45: Income Statement Table
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•—
â•‘                      â•‘ 2023   â•‘ 2022   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•£
â•‘ Revenue              â•‘ $383B  â•‘ $365B  â•‘
â•‘ Gross Profit         â•‘ $169B  â•‘ $161B  â•‘
â•‘ Operating Income     â•‘ $114B  â•‘ $108B  â•‘
â•‘ Net Income           â•‘ $97B   â•‘ $94B   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•
```

### **AI Processing:**
```
1. Extract table â†’ Clean data
2. Convert "$383B" â†’ 383000000000.0
3. Classify as "income_statements"
4. Calculate metrics:
   - Profit Margin: 97B Ã· 383B = 25.3%
   - Gross Margin: 169B Ã· 383B = 44.1%
   - Revenue Growth: (383B - 365B) Ã· 365B = 4.9%
5. Generate insights:
   - "Strong profit margin of 25.3%"
   - "Moderate revenue growth of 4.9%"
```

### **Output:**
```json
{
  "tables": {
    "income_statements": [{
      "metadata": {"page": 45, "accuracy": 0.95},
      "structured_data": {
        "line_items": ["Revenue", "Gross Profit", ...],
        "periods": ["2023", "2022"],
        "values": {
          "Revenue": {"2023": 383000000000, "2022": 365000000000}
        }
      }
    }]
  },
  "insights": {
    "financial_metrics": {
      "profit_margin": 0.253,
      "revenue_growth": 0.049,
      "gross_margin": 0.441
    },
    "key_findings": [
      "Strong profit margin of 25.3%",
      "Revenue growth of 4.9% year-over-year"
    ]
  }
}
```

---

## **ðŸ’¡ Classroom Activities**

### **Activity 1: The Table Detective**
```python
# Task: "Extract data from messy table"
messy_data = [
    ["Revenue", "$1,234M", "$1,100M"],
    ["Cost of Sales", "($800M)", "($750M)"],
    ["Gross Profit", "$434M", "$350M"],
    ["EPS", "$2.50", "$2.25"]
]

# Students: Write code to:
# 1. Clean column names
# 2. Convert financial values
# 3. Calculate gross margin
# 4. Find EPS growth

# Learn: Financial data cleaning patterns
```

### **Activity 2: The Ratio Calculator**
```python
# Task: "Calculate financial health"
given_data = {
    "revenue": 1000000,
    "net_income": 150000,
    "total_assets": 2000000,
    "total_liabilities": 800000,
    "equity": 1200000
}

# Students calculate:
# 1. Profit margin (net_income Ã· revenue)
# 2. Debt-to-assets (liabilities Ã· assets)
# 3. Debt-to-equity (liabilities Ã· equity)
# 4. Return on equity (net_income Ã· equity)

# Learn: Key financial ratios
```

### **Activity 3: The Trend Analyzer**
```python
# Task: "Spot trends in multi-year data"
revenue_data = {
    "2020": 1000000,
    "2021": 1100000,
    "2022": 1250000,
    "2023": 1400000
}

# Students:
# 1. Calculate year-over-year growth rates
# 2. Calculate 3-year CAGR
# 3. Identify if growth is accelerating/decelerating
# 4. Predict next year using trend

# Learn: Time series analysis basics
```

---


## **ðŸŽ¯ Key Takeaways**

1. **Financial documents are treasure troves** - But data is trapped in PDFs
2. **Table extraction is complex** - Multiple formats, edge cases
3. **Value conversion is critical** - $1.2B â‰  1.2!
4. **Automatic analysis saves hours** - Instant insights from raw data
5. **Structured data enables everything** - Queries, comparisons, alerts

**This transforms financial analysis from:**
- **"Manual data entry"** â†’ **"Automated extraction"**
- **"PDF reading"** â†’ **"Database querying"**
- **"Static reports"** â†’ **"Interactive analysis"**

**Question for discussion:** If you could add one more type of financial document or data source for this system to process, what would it be and why?

#### Create `src/financial_rag/processing/document_understanding.py`

```python
import pdfplumber
import pandas as pd
import camelot
import cv2
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
import re
from loguru import logger

class FinancialDocumentProcessor:
    """Process financial documents with table extraction and understanding"""
    
    def __init__(self):
        self.table_analyzer = FinancialTableAnalyzer()
        self.chart_processor = ChartProcessor()
    
    def extract_financial_tables(self, pdf_path: str) -> Dict[str, Any]:
        """Extract and analyze financial tables from PDF"""
        try:
            tables_data = {
                'income_statements': [],
                'balance_sheets': [],
                'cash_flow_statements': [],
                'other_tables': []
            }
            
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    # Extract tables using camelot for better accuracy
                    camelot_tables = camelot.read_pdf(
                        pdf_path, 
                        pages=str(page_num+1),
                        flavor='lattice'
                    )
                    
                    for table in camelot_tables:
                        table_data = self.process_financial_table(
                            table.df, page_num, table.parsing_report
                        )
                        
                        if table_data:
                            table_type = self.classify_table_type(table_data)
                            tables_data[table_type].append(table_data)
                    
                    # Fallback: pdfplumber tables
                    pdfplumber_tables = page.extract_tables()
                    for table in pdfplumber_tables:
                        if table and len(table) > 1:  # Valid table with header
                            df = pd.DataFrame(table[1:], columns=table[0])
                            table_data = self.process_financial_table(
                                df, page_num, {'accuracy': 0.7}
                            )
                            
                            if table_data:
                                table_type = self.classify_table_type(table_data)
                                tables_data[table_type].append(table_data)
            
            # Analyze extracted tables
            analyzed_tables = self.analyze_all_tables(tables_data)
            
            return analyzed_tables
            
        except Exception as e:
            logger.error(f"Error extracting tables from {pdf_path}: {e}")
            return {}

# **Why two engines?**
# - **Camelot:** Great for grid-based tables (Excel-like)
# - **pdfplumber:** Better for complex layouts, merged cells
# - **Together:** Catch 95% of all tables!




    
    def process_financial_table(self, df: pd.DataFrame, page_num: int, 
                              parsing_report: Dict) -> Optional[Dict]:
        """Process and clean financial table"""
        try:
            # Clean the dataframe
            df_clean = self.clean_dataframe(df)
            
            if df_clean.empty or len(df_clean.columns) < 2:
                return None
            
            # Extract metadata
            table_metadata = {
                'page_number': page_num + 1,
                'parsing_accuracy': parsing_report.get('accuracy', 0),
                'shape': df_clean.shape,
                'columns': df_clean.columns.tolist(),
                'data_types': self.infer_data_types(df_clean)
            }
            
            # Convert to structured data
            structured_data = self.convert_to_structured_data(df_clean)
            
            return {
                'metadata': table_metadata,
                'raw_data': df_clean.to_dict('records'),
                'structured_data': structured_data,
                'cleaned_df': df_clean
            }
            
        except Exception as e:
            logger.error(f"Error processing table: {e}")
            return None
    
    def clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Clean and normalize dataframe"""
        # Remove empty rows and columns
        df_clean = df.dropna(how='all').dropna(axis=1, how='all')
        
        # Clean column names
        df_clean.columns = [self.clean_column_name(col) for col in df_clean.columns]
        
        # Remove duplicate rows
        df_clean = df_clean.drop_duplicates()
        
        # Convert numeric columns
        for col in df_clean.columns:
            if col != 'line_item':  # Assuming first column is description
                df_clean[col] = df_clean[col].apply(self.convert_financial_value)
        
        return df_clean
    
    def clean_column_name(self, name: Any) -> str:
        """Clean column names"""
        if pd.isna(name):
            return 'unknown'
        
        name_str = str(name).strip().lower()
        # Remove special characters but keep periods for dates
        name_str = re.sub(r'[^\w\s.]', '', name_str)
        return name_str
    
    def convert_financial_value(self, value: Any) -> Optional[float]:
        """Convert financial values to numbers"""
        if pd.isna(value):
            return None
        
        value_str = str(value).strip()
        
        # Remove common financial notation
        value_str = value_str.replace('$', '').replace(',', '').replace('(', '-').replace(')', '')
        
        # Handle percentage values
        if '%' in value_str:
            value_str = value_str.replace('%', '')
            try:
                return float(value_str) / 100
            except:
                return None
        
        # Handle text representations
        if 'million' in value_str.lower():
            value_str = value_str.lower().replace('million', '').strip()
            try:
                return float(value_str) * 1_000_000
            except:
                return None
        
        if 'billion' in value_str.lower():
            value_str = value_str.lower().replace('billion', '').strip()
            try:
                return float(value_str) * 1_000_000_000
            except:
                return None
        
        try:
            return float(value_str)
        except:
            return None
    
    def infer_data_types(self, df: pd.DataFrame) -> Dict[str, str]:
        """Infer data types for columns"""
        data_types = {}
        
        for col in df.columns:
            # Check if column contains mostly numeric values
            numeric_count = df[col].apply(lambda x: isinstance(x, (int, float))).sum()
            
            if numeric_count / len(df) > 0.7:
                data_types[col] = 'numeric'
            else:
                data_types[col] = 'text'
        
        return data_types
    
    def convert_to_structured_data(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Convert table to structured financial data"""
        structured = {
            'line_items': [],
            'periods': [],
            'values': {}
        }
        
        # Assume first column is line items
        if len(df.columns) > 0:
            line_items = df.iloc[:, 0].tolist()
            structured['line_items'] = [str(item) for item in line_items if pd.notna(item)]
        
        # Assume other columns are time periods
        if len(df.columns) > 1:
            periods = df.columns[1:].tolist()
            structured['periods'] = periods
            
            # Extract values for each line item and period
            for i, line_item in enumerate(structured['line_items']):
                if i < len(df):
                    values = {}
                    for j, period in enumerate(periods):
                        if j + 1 < len(df.columns):
                            value = df.iloc[i, j + 1]
                            if pd.notna(value):
                                values[period] = value
                    
                    if values:
                        structured['values'][line_item] = values
        
        return structured
    
    def classify_table_type(self, table_data: Dict) -> str:
        """Classify the type of financial table"""
        line_items = table_data['structured_data'].get('line_items', [])
        line_items_lower = [str(item).lower() for item in line_items]
        
        # Income statement indicators
        income_indicators = ['revenue', 'sales', 'gross profit', 'operating income', 'net income', 'eps']
        if any(indicator in ' '.join(line_items_lower) for indicator in income_indicators):
            return 'income_statements'
        
        # Balance sheet indicators
        balance_indicators = ['assets', 'liabilities', 'equity', 'cash', 'inventory', 'debt']
        if any(indicator in ' '.join(line_items_lower) for indicator in balance_indicators):
            return 'balance_sheets'
        
        # Cash flow indicators
        cash_flow_indicators = ['operating activities', 'investing activities', 'financing activities', 'cash flow']
        if any(indicator in ' '.join(line_items_lower) for indicator in cash_flow_indicators):
            return 'cash_flow_statements'
        
        return 'other_tables'
    
    def analyze_all_tables(self, tables_data: Dict) -> Dict[str, Any]:
        """Analyze all extracted tables for insights"""
        insights = {
            'financial_metrics': {},
            'trends': {},
            'key_findings': []
        }
        
        # Analyze income statements
        for table in tables_data['income_statements']:
            metrics = self.table_analyzer.analyze_income_statement(table)
            insights['financial_metrics'].update(metrics)
        
        # Analyze balance sheets
        for table in tables_data['balance_sheets']:
            metrics = self.table_analyzer.analyze_balance_sheet(table)
            insights['financial_metrics'].update(metrics)
        
        # Analyze trends
        insights['trends'] = self.table_analyzer.analyze_trends(tables_data)
        
        # Generate key findings
        insights['key_findings'] = self.generate_key_findings(insights)
        
        return {
            'tables': tables_data,
            'insights': insights
        }
    
    def generate_key_findings(self, insights: Dict) -> List[str]:
        """Generate natural language key findings"""
        findings = []
        metrics = insights.get('financial_metrics', {})
        trends = insights.get('trends', {})
        
        # Revenue findings
        if 'revenue_growth' in metrics:
            growth = metrics['revenue_growth']
            if growth > 0.1:
                findings.append(f"Strong revenue growth of {growth:.1%}")
            elif growth < 0:
                findings.append(f"Revenue decline of {abs(growth):.1%}")
        
        # Profitability findings
        if 'profit_margin' in metrics:
            margin = metrics['profit_margin']
            if margin > 0.2:
                findings.append(f"High profit margin of {margin:.1%}")
            elif margin < 0.05:
                findings.append(f"Low profit margin of {margin:.1%}")
        
        # Trend findings
        for metric, trend in trends.items():
            if trend.get('direction') == 'increasing':
                findings.append(f"Increasing trend in {metric}")
            elif trend.get('direction') == 'decreasing':
                findings.append(f"Decreasing trend in {metric}")
        
        return findings


class FinancialTableAnalyzer:
    """Analyze financial tables for insights"""
    
    def analyze_income_statement(self, table_data: Dict) -> Dict[str, float]:
        """Analyze income statement table"""
        metrics = {}
        structured_data = table_data['structured_data']
        
        # Extract key metrics
        revenue = self.extract_metric(structured_data, 'revenue')
        net_income = self.extract_metric(structured_data, 'net income')
        gross_profit = self.extract_metric(structured_data, 'gross profit')
        operating_income = self.extract_metric(structured_data, 'operating income')
        
        if revenue and net_income:
            metrics['profit_margin'] = net_income / revenue

# **Calculates key ratios:**
# - **Profit Margin** = Net Income Ã· Revenue
# - **Gross Margin** = Gross Profit Ã· Revenue  
# - **Operating Margin** = Operating Income Ã· Revenue
# - **Revenue Growth** = (This Year - Last Year) Ã· Last Year

        
        if revenue and gross_profit:
            metrics['gross_margin'] = gross_profit / revenue
        
        if revenue and operating_income:
            metrics['operating_margin'] = operating_income / revenue
        
        # Calculate growth if multiple periods
        periods = structured_data.get('periods', [])
        if len(periods) >= 2 and revenue:
            current_rev = self.extract_metric_for_period(structured_data, 'revenue', periods[-1])
            prev_rev = self.extract_metric_for_period(structured_data, 'revenue', periods[-2])
            
            if current_rev and prev_rev and prev_rev != 0:
                metrics['revenue_growth'] = (current_rev - prev_rev) / prev_rev
        
        return metrics
    
    def analyze_balance_sheet(self, table_data: Dict) -> Dict[str, float]:
        """Analyze balance sheet table"""
        metrics = {}
        structured_data = table_data['structured_data']
        
        # Extract key metrics
        total_assets = self.extract_metric(structured_data, 'total assets')
        total_liabilities = self.extract_metric(structured_data, 'total liabilities')
        equity = self.extract_metric(structured_data, 'total equity')
        cash = self.extract_metric(structured_data, 'cash')
        
        if total_assets and total_liabilities:
            metrics['debt_to_assets'] = total_liabilities / total_assets # 40% debt ratio


# **Financial health metrics:**
# - **Debt-to-Assets** = How much is financed by debt
# - **Debt-to-Equity** = Debt compared to shareholder money
# - **Cash Ratio** = How much liquidity (cash cushion)

        
        if equity and total_liabilities:
            metrics['debt_to_equity'] = total_liabilities / equity
        
        if cash and total_assets:
            metrics['cash_ratio'] = cash / total_assets
        
        return metrics
    
    def extract_metric(self, structured_data: Dict, metric_name: str) -> Optional[float]:
        """Extract a metric from structured data"""
        values = structured_data.get('values', {})
        
        for line_item, period_values in values.items():
            if metric_name.lower() in line_item.lower():
                # Get the most recent value
                periods = structured_data.get('periods', [])
                if periods:
                    latest_period = periods[-1]
                    return period_values.get(latest_period)

        return None
# **Why fuzzy matching?**
# Tables might label things differently:
# - "Revenue" vs "Sales" vs "Total Revenue"
# - "Net Income" vs "Profit" vs "Earnings"
# - "Assets" vs "Total Assets" vs "Assets, Total"

    
    def extract_metric_for_period(self, structured_data: Dict, metric_name: str, 
                                period: str) -> Optional[float]:
        """Extract a metric for a specific period"""
        values = structured_data.get('values', {})
        
        for line_item, period_values in values.items():
            if metric_name.lower() in line_item.lower():
                return period_values.get(period)
        
        return None
    
    def analyze_trends(self, tables_data: Dict) -> Dict[str, Any]:
        """Analyze trends across multiple periods"""
        trends = {}
        
        # Analyze income statement trends
        for table in tables_data['income_statements']:
            structured_data = table['structured_data']
            periods = structured_data.get('periods', [])
            
            if len(periods) >= 2:
                for line_item, values in structured_data.get('values', {}).items():
                    if len(values) >= 2:
                        period_values = list(values.items())
                        current_val = period_values[-1][1]
                        prev_val = period_values[-2][1]
                        
                        if prev_val and prev_val != 0:
                            growth = (current_val - prev_val) / prev_val
                            direction = 'increasing' if growth > 0 else 'decreasing'
                            
                            trends[line_item] = {
                                'growth_rate': growth,
                                'direction': direction,
                                'current_value': current_val,
                                'previous_value': prev_val
                            }
        
        return trends


class ChartProcessor:
    """Process and extract data from financial charts"""
    
    def extract_chart_data(self, image_path: str) -> Dict[str, Any]:
        """Extract data from financial charts (simplified implementation)"""
        # In production, use computer vision models to:
        # 1. Detect chart type (line, bar, pie)
        # 2. Read axis labels and values
        # 3. Extract data points
        # 4. Calculate trends

        # For now, return mock data structure

        return {
            'chart_type': self.detect_chart_type(image_path),
            'data_points': [],
            'trend': 'unknown',
            'confidence': 0.0
        }
    
    def detect_chart_type(self, image_path: str) -> str:
        """Detect the type of financial chart"""
        # Simplified implementation
        return 'line_chart'  # In production, use CV to detect chart type
```

### **Step 3: Multi-Modal Analysis Agent**

#### Create `src/financial_rag/agents/multi_modal_analyst.py`
# **ðŸ§  The AI Master Analyst: Multi-Modal Financial Intelligence!**

Good morning class! Today we're looking at the **most advanced evolution** of our Financial AI - the Multi-Modal Analyst! This isn't just one AI anymore; this is like having an **entire Wall Street research team** in one system that can analyze **text, audio, documents, and real-time data** simultaneously!

---

## **ðŸš€ What This Code Creates**

This code builds the **ultimate financial AI** that:
1. **ðŸ‘‚ Listens to earnings calls** (audio analysis)
2. **ðŸ“„ Reads financial documents** (PDF/table extraction)
3. **ðŸ“Š Analyzes real-time markets** (live data)
4. **ðŸ“ˆ Processes historical data** (SEC filings)
5. **ðŸ¤” Synthesizes everything** into one coherent analysis

**Think of it like:** Bloomberg Terminal + Siri + PDF Reader + Financial Analyst all merged into one super-intelligence!

---

## **ðŸŽ¯ The Multi-Modal Revolution**

### **Traditional Single-Mode Analysis:**
```
Question: "How did Apple's earnings call go?"
- Text-only AI: "Based on the transcript..." (missing tone)
- Audio-only AI: "They sounded positive..." (missing numbers)
- Data-only AI: "Revenue was $89.5B..." (missing context)
```

### **Multi-Modal Analysis:**
```
"Based on the earnings call:
1. **Audio Analysis:** CEO sounded very confident (+0.45 sentiment)
2. **Transcript:** Mentioned 'record iPhone sales' 15 times
3. **Financials:** Revenue $89.5B (+8% YoY), EPS $1.46 (beat)
4. **Market Reaction:** Stock up 3.2% in after-hours
5. **Guidance:** Raised Q4 forecast to $92-95B
Overall: Strong results with positive outlook."
```

**All perspectives, one answer!**

---

## **ðŸ”§ The Inheritance Chain: Building on Everything**

### **The Evolution:**
```python
FinancialAgent (Base)
    â†“
RealTimeAnalystAgent (Adds live data)
    â†“
MultiModalAnalystAgent (Adds audio + documents)
```

**Why inheritance rocks:**
- **Reuse all previous code** - Don't reinvent the wheel!
- **Layer capabilities** - Each generation adds new powers
- **Single interface** - Same `.analyze()` method, but smarter!

**It's like:** Starting with a regular car â†’ Adding a jet engine â†’ Adding submarine capabilities!

---

## **ðŸŽ­ The Four Data Streams**

### **1. Audio Stream (Earnings Calls)**
```python
call_analysis = self.audio_processor.transcribe_earnings_call(audio_path)
# Gets: Transcript, speaker IDs, sentiment, key metrics
```

**Why audio matters:**
- **Tone reveals truth** - Numbers say "good", tone says "worried"
- **Q&A sessions** - Analysts' tough questions reveal concerns
- **Spontaneous answers** - Less scripted than written reports

### **2. Real-Time Stream (Market Data)**
```python
real_time_context = await self.get_real_time_context([ticker])
# Gets: Current price, market reaction, sentiment
```

**Connects call to market:**
- "CEO sounded positive" + "Stock up 5%" = Strong correlation
- "CFO cautious" + "Stock flat" = Market agrees with caution

### **3. Historical Stream (SEC Filings)**
```python
historical_analysis = self.agent.analyze("Historical context for Apple")
# Gets: Past performance, risk factors, trends
```

**Provides context:**
- Is this growth unusual? (vs. historical averages)
- Are risks increasing or decreasing?
- How does guidance compare to past?

### **4. Document Stream (PDF Reports)**
```python
# Could integrate with document_processor
tables = self.document_processor.extract_financial_tables("10-K.pdf")
# Gets: Clean financial tables for deeper analysis
```

**The hard numbers:** For when transcript mentions aren't enough!

---

## **ðŸ” The Earnings Call Analysis Pipeline**

### **Step-by-Step Processing:**
```
1. Upload earnings call audio
2. Transcribe with speaker identification
3. Extract financial metrics (revenue, EPS, guidance)
4. Analyze sentiment per speaker
5. Get real-time market context
6. Retrieve historical analysis
7. Synthesize all insights
8. Generate investment implications
```

**All automated, takes minutes instead of hours!**




```python
from typing import Dict, List, Any, Optional
import asyncio
from datetime import datetime
import os
from loguru import logger

from financial_rag.agents.real_time_analyst import RealTimeAnalystAgent
from financial_rag.processing.audio_processor import EarningsCallProcessor
from financial_rag.processing.document_understanding import FinancialDocumentProcessor

class MultiModalAnalystAgent(RealTimeAnalystAgent):
    """Agent capable of multi-modal financial analysis"""
    
    def __init__(self, vector_store, enable_monitoring: bool = True):
        super().__init__(vector_store, enable_monitoring)
        self.audio_processor = EarningsCallProcessor()
        self.document_processor = FinancialDocumentProcessor()
        self.multimodal_context = {}
        
    async def analyze_earnings_call(self, audio_path: str, ticker: str) -> Dict[str, Any]:
        """Comprehensive earnings call analysis"""
        try:
            logger.info(f"Analyzing earnings call for {ticker}: {audio_path}")
            
            # Transcribe and analyze audio
            call_analysis = self.audio_processor.transcribe_earnings_call(audio_path)
            
            # Get real-time context
            real_time_context = await self.get_real_time_context([ticker])
            
            # Combine with historical analysis
            historical_analysis = await asyncio.get_event_loop().run_in_executor(
                None, self.agent.analyze,
                f"Provide historical context and risk factors for {ticker}"
            )
            
            # Generate comprehensive insights
            insights = self.generate_earnings_insights(
                call_analysis, real_time_context, historical_analysis
            )
            
            # Store in multimodal context
            self.multimodal_context[f'earnings_{ticker}_{datetime.now().isoformat()}'] = {
                'call_analysis': call_analysis,
                'real_time_context': real_time_context,
                'historical_analysis': historical_analysis,
                'insights': insights
            }
            
            return {
                'ticker': ticker,
                'call_analysis': call_analysis,
                'real_time_context': real_time_context,
                'historical_analysis': historical_analysis,
                'insights': insights,
                'summary': self.generate_earnings_summary(insights)
            }
            
        except Exception as e:
            logger.error(f"Error analyzing earnings call: {e}")
            raise
    
    def generate_earnings_insights(self, call_analysis: Dict, real_time_context: Dict, 
                                 historical_analysis: Dict) -> Dict[str, Any]:
        """Generate insights from earnings call analysis"""
        insights = {
            'sentiment_analysis': {},      # How did they sound?
            'key_metrics': {},             # What numbers matter?
            'guidance_analysis': {},       # What's the future look like?
            'market_reaction': {},         # How did market respond?
            'investment_implications': []  # What should investors do?
        }
        
        # Sentiment insights
        sentiment_data = call_analysis.get('sentiment_analysis', {})
        insights['sentiment_analysis'] = self.analyze_call_sentiment(sentiment_data)
        
        # Metric insights
        key_metrics = call_analysis.get('key_metrics', {})
        insights['key_metrics'] = self.analyze_call_metrics(key_metrics)
        
        # Guidance analysis
        guidance = key_metrics.get('guidance', {})
        insights['guidance_analysis'] = self.analyze_guidance(guidance)
        
        # Market reaction analysis
        market_data = real_time_context.get('market_data', {})
        insights['market_reaction'] = self.analyze_market_reaction(market_data)
        
        # Investment implications
        insights['investment_implications'] = self.generate_investment_implications(
            insights, historical_analysis
        )
        
        return insights
    
    def analyze_call_sentiment(self, sentiment_data: Dict) -> Dict[str, Any]:
        """Analyze sentiment from earnings call"""
        overall = sentiment_data.get('overall', {})
        by_speaker = sentiment_data.get('by_speaker', {})
        
        return {
            'overall_sentiment': self.get_sentiment_label(overall.get('average_polarity', 0)),
            'sentiment_score': overall.get('average_polarity', 0),
            'speaker_sentiments': {
                speaker: {
                    'sentiment': self.get_sentiment_label(data.get('average_polarity', 0)),
                    'score': data.get('average_polarity', 0),
                    'confidence': data.get('average_subjectivity', 0)
                }
                for speaker, data in by_speaker.items()
            },
            'key_positive_points': self.extract_positive_statements(sentiment_data),
            'key_concerns': self.extract_concerns(sentiment_data)
        }
    
    def get_sentiment_label(self, score: float) -> str:
        """Convert sentiment score to label"""
        if score > 0.2:
            return 'very_positive'
        elif score > 0.05:
            return 'positive'
        elif score > -0.05:
            return 'neutral'
        elif score > -0.2:
            return 'negative'
        else:
            return 'very_negative'
# **Real example:**
# - CEO: +0.45 â†’ `very_positive`
# - CFO: +0.12 â†’ `positive` 
# - Analyst questions: -0.08 â†’ `slightly_negative`
# - **Overall:** Mixed but leaning positive


    
    def extract_positive_statements(self, sentiment_data: Dict) -> List[str]:
        """Extract positive statements from call"""
        # Implementation would analyze transcript segments with high positive sentiment
        return ["Strong growth in key segments", "Confidence in future outlook"]
    
    def extract_concerns(self, sentiment_data: Dict) -> List[str]:
        """Extract concerns from call"""
        # Implementation would analyze transcript segments with negative sentiment
        return ["Supply chain challenges", "Macroeconomic headwinds"]
    
    def analyze_call_metrics(self, key_metrics: Dict) -> Dict[str, Any]:
        """Analyze key metrics from earnings call"""
        analysis = {
            'revenue_trend': self.analyze_revenue_trend(key_metrics.get('revenue', [])),
            'profitability': self.analyze_profitability(key_metrics.get('eps', [])),
            'growth_indicators': self.analyze_growth_indicators(key_metrics.get('growth_rates', [])),
            'key_announcements': key_metrics.get('key_announcements', [])
        }
        
        return analysis
    
    def analyze_revenue_trend(self, revenue_data: List) -> Dict[str, Any]:
        """Analyze revenue trends"""
        if not revenue_data:
            return {'trend': 'unknown', 'confidence': 0}
        
        # Simple trend analysis
        return {'trend': 'growing', 'confidence': 0.8}
    
    def analyze_profitability(self, eps_data: List) -> Dict[str, Any]:
        """Analyze profitability trends"""
        if not eps_data:
            return {'trend': 'unknown', 'confidence': 0}
        
        # Simple profitability analysis
        return {'trend': 'stable', 'confidence': 0.7}
    
    def analyze_growth_indicators(self, growth_rates: List) -> Dict[str, Any]:
        """Analyze growth indicators"""
        if not growth_rates:
            return {'indicators': [], 'overall_growth': 'unknown'}
        
        positive_growth = [g for g in growth_rates if g.get('rate', 0) > 0]
        growth_strength = len(positive_growth) / len(growth_rates) if growth_rates else 0
        
        return {
            'indicators': growth_rates,
            'overall_growth': 'strong' if growth_strength > 0.7 else 'moderate'
        }
    
    def analyze_guidance(self, guidance: Dict) -> Dict[str, Any]:
        """Analyze forward guidance"""
        sentences = guidance.get('sentences', [])
        confidence = guidance.get('confidence', 0)
        
        return {
            'guidance_statements': sentences,
            'confidence': confidence,
            'sentiment': self.analyze_guidance_sentiment(sentences),
            'key_points': self.extract_guidance_key_points(sentences)
        }
    
    def analyze_guidance_sentiment(self, guidance_sentences: List[str]) -> str:
        """Analyze sentiment of guidance statements"""
        if not guidance_sentences:
            return 'neutral'
        
        # Simple keyword-based sentiment analysis
        positive_words = ['strong', 'growth', 'increase', 'improve', 'optimistic']
        negative_words = ['challenge', 'headwind', 'uncertain', 'pressure', 'decline']
        
        text = ' '.join(guidance_sentences).lower()
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'

# **Example guidance:**
# - "We expect strong growth in Q4" â†’ `positive`
# - "Despite headwinds, we remain confident" â†’ `mixed`
# - "Uncertain macroeconomic environment" â†’ `negative`


    
    def extract_guidance_key_points(self, guidance_sentences: List[str]) -> List[str]:
        """Extract key points from guidance"""
        key_points = []
        
        for sentence in guidance_sentences:
            # Extract quantitative guidance
            if any(word in sentence.lower() for word in ['expect', 'target', 'forecast', 'guidance']):
                key_points.append(sentence)
        
        return key_points[:3]  # Return top 3 key points
    

## **ðŸŽ“ Real-World Example: Tesla Earnings Call**

### **Multi-Modal Data Collection:**
```
ðŸŽ¤ Audio: Elon Musk sounds enthusiastic about Cybertruck
ðŸ“ Transcript: Mentions "record production" 12 times
ðŸ’° Financials: Revenue $23.4B, EPS $0.66 (missed by $0.02)
ðŸ“ˆ Market: Stock down 5% after hours
ðŸ“Š Historical: Usually beats estimates by $0.10+
ðŸŽ¯ Guidance: Maintains 1.8M vehicle delivery target
```

### **AI Synthesis:**
```json
{
  "sentiment_analysis": {
    "overall_sentiment": "mixed",
    "ceo_sentiment": "very_positive",
    "cfo_sentiment": "neutral",
    "key_positive_points": ["Cybertruck enthusiasm", "Production records"],
    "key_concerns": ["Margin pressure", "EPS miss"]
  },
  "key_metrics": {
    "revenue_trend": "growing",
    "profitability": "declining",
    "growth_indicators": "moderate"
  },
  "market_reaction": {
    "price_change": -5.2,
    "volume": "high",
    "sentiment": "negative"
  },
  "investment_implications": [
    "Short-term pressure due to EPS miss",
    "Long-term thesis intact with production growth",
    "Monitor margin trends in next quarter"
  ]
}
```

### **Final Summary:**
```
Tesla Q3: Mixed results with positive long-term signals.
Despite EPS miss (-$0.02), production remains strong and 
CEO enthusiasm high. Market reacted negatively (-5.2%), 
but guidance unchanged. Key watch: margin recovery.
```

---

## **ðŸ’¡ Classroom Activities**

### **Activity 1: The Multi-Modal Detective**
```python
# Task: "Analyze conflicting signals"
given_data = {
    "audio_sentiment": 0.35,        # Very positive
    "financial_results": {"eps": 0.50, "expected": 0.55},  # Miss
    "market_reaction": -2.5,        # Slightly down
    "guidance": "We expect challenges ahead"  # Cautious
}

# Students: Write analysis reconciling all signals
# Answer might be: "Management optimistic despite miss, market cautious"

# Learn: Interpreting conflicting information
```

### **Activity 2: The Guidance Interpreter**
```python
# Task: "Read between the lines in guidance"
guidance_statements = [
    "We remain confident in our long-term strategy",
    "Short-term headwinds may impact Q4 results",
    "We're investing heavily in future growth",
    "Market conditions remain challenging"
]

# Students:
# 1. Analyze sentiment (positive/negative/neutral)
# 2. Extract key points
# 3. Write executive summary
# 4. Predict market reaction

# Learn: Corporate communication analysis
```

### **Activity 3: The Investment Thesis Builder**
```python
# Task: "Build buy/hold/sell recommendation"
data_points = [
    "Revenue growth: +15% YoY",
    "Profit margin: declining from 25% to 20%",
    "CEO sentiment: very positive",
    "Market reaction: stock up 8%",
    "Guidance: raised next quarter forecast",
    "Competition: increasing in key markets"
]

# Students weigh each point, build thesis
# Learn: Balanced investment analysis
```

---

## **âš¡ Advanced Features to Add**

### **1. Cross-Corporate Comparison:**
```python
# Compare Tesla vs. Ford earnings calls
tesla_sentiment = analyze_call("tesla_q3.mp3")
ford_sentiment = analyze_call("ford_q3.mp3")
comparison = compare_sentiment(tesla_sentiment, ford_sentiment)
# "Tesla more optimistic about EV adoption than Ford"
```

### **2. Earnings Call Bingo:**
```python
# Track common phrases
bingo_phrases = {
    "strong demand": 0,
    "supply chain": 0,
    "macro headwinds": 0,
    "cautiously optimistic": 0
}
# "This earnings call hit 3 of 4 common phrases!"
```

### **3. Whisper vs. Reality:**
```python
# Detect when tone doesn't match words
if sentiment_score > 0.3 but "challenging" in transcript:
    flag = "Overly optimistic tone despite challenges"
# Important for detecting management spin
```

### **4. Analyst Question Analysis:**
```python
# Analyze which analysts ask tough questions
if "Goldman Sachs" in analyst_questions:
    if sentiment(questions) < -0.2:
        insights.append("Goldman asking tough questions")
# Institutional sentiment indicator!
```

---

## **ðŸ” Production Considerations**

### **Audio Processing Costs:**
```python
# Whisper model sizes
model_sizes = {
    "tiny": "Fast, okay accuracy (~1GB RAM)",
    "base": "Good balance (~1.5GB RAM)", 
    "small": "Better accuracy (~3GB RAM)",
    "medium": "High accuracy (~6GB RAM)",
    "large": "Best accuracy (~12GB RAM)"
}
# Choose based on needs: base for speed, large for accuracy
```

### **Storage Strategy:**
```python
# Store processed calls
call_id = f'{ticker}_{quarter}_{year}'
store_in_database({
    "call_id": call_id,
    "transcript": "...",
    "metrics": {...},
    "sentiment": {...},
    "processing_time": 45.2
})
# Enable historical comparison across quarters!
```

### **Rate Limiting:**
```python
# Don't process too many calls at once
MAX_CONCURRENT_CALLS = 3
MAX_CALLS_PER_HOUR = 20
# Earnings season: 1000+ calls in 2 weeks!
```

---

## **ðŸš€ Integration with Trading Systems**

### **Real-Time Alerts:**
```python
# During earnings call (live!)
if "missed expectations" in transcript:
    send_alert("âš ï¸ Company missing earnings expectations")
    
if sentiment_score < -0.3:
    send_alert("ðŸ˜Ÿ Management sounding very negative")
```

### **Portfolio Impact Analysis:**
```python
# For portfolio companies
portfolio = ["AAPL", "MSFT", "GOOGL", "AMZN"]
for ticker in portfolio:
    if earnings_today(ticker):
        analysis = analyze_earnings_call(ticker)
        update_portfolio_recommendation(ticker, analysis)
```

### **Research Report Generation:**
```python
# Auto-generate reports
report = generate_earnings_report(analysis)
# Includes: Summary, metrics, sentiment, guidance, implications
# Saves analysts hours of work!
```

---

## **ðŸŽ¯ Key Takeaways**

1. **Multi-modal = Multi-perspective** - Audio + text + data + context
2. **Earnings calls = Goldmine of insights** - Beyond just numbers
3. **Sentiment analysis = Market predictor** - Tone matters as much as content
4. **Synthesis = Superpower** - Connecting all data streams
5. **Automation = Scalability** - Process 1000s of calls vs. manual review

**This transforms financial analysis from:**
- **"Single perspective"** â†’ **"360-degree view"**
- **"Manual listening"** â†’ **"Automated intelligence"**
- **"Isolated data points"** â†’ **"Connected insights"**
- **"Reactive analysis"** â†’ **"Proactive intelligence"**

**Question for discussion:** If you could add one more data source or analysis capability to this multi-modal system, what would it be and why?


